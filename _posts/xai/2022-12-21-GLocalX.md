---
layout: post
title: "GLocalX"
date: "2022-12-21 12:00:00"
year: 2022
tags: "seminar"
location: "Room 1 @ Officine Garibaldi - il Cantiere delle Idee, Via Vincenzo Gioberti, 39, 56124 Pisa PI, Italy"
presenter: "Presenter: Mattia Setzu"
---
<h5>Presenter: Mattia Setzu</h5>
<em>Location: Room 1 @ Officine Garibaldi - il Cantiere delle Idee, Via Vincenzo Gioberti, 39, 56124 Pisa PI, Italy<em>
<br>
<hr>
<br><br><p><strong>Abstract<strong><br><p><p><strong><strong>Artificial Intelligence AI has come to prominence as one of the major components of our society, with applications in most aspects of our lives. In this field, complex and highly nonlinear machine learning models such as ensemble models, deep neural networks, and Support Vector Machines have consistently shown remarkable accuracy in solving complex tasks. Although accurate, AI models often are black boxes which we are not able to understand. Relying on these models has a multifaceted impact and raises significant concerns about their transparency. Applications in sensitive and critical domains are a strong motivational factor in trying to understand the behavior of black boxes. We propose to address this issue by providing an interpretable layer on top of black box models by aggregating local explanations. We present GLocalX, a localfirst model agnostic explanation method. Starting from local explanations expressed in form of local decision rules, GLocalX iteratively generalizes them into global explanations by hierarchically aggregating them. Our goal is to learn accurate yet simple interpretable models to emulate the given black box, and, if possible, replace it entirely. We validate GLocalX in a set of experiments in standard and constrained settings with limited or no access to either data or local explanations. Experiments show that GLocalX is able to accurately emulate several models with simple and small models, reaching stateoftheart performance against natively global solutions. Our findings show how it is often possible to achieve a high level of both accuracy and comprehensibility of classification models, even in complex domains with highdimensional data, without necessarily trading one property for the other. This is a key requirement for a trustworthy AI, necessary for adoption in highstakes decision making applications.<br><p><br><br><br><br><br><br>Microsoft Teams meeting<br><br><b>Join on your computer, mobile app or room device<b><a hrefhttps:teams.microsoft.comlmeetupjoin193a9a85abed0d8544a8bc86e6f8f42e599d40thread.tacv21671204581740context7b22Tid223a22c7456b31a22047f5be52473828670aa1222c22Oid223a22729b4d16056746a8a742d2ae1bf09a4a227d><u>Click here to join the meeting<u><a><br><br>Meeting ID: 340 547 739 918<br>Passcode: FNLU3Y<br><a hrefhttps:www.microsoft.comenusmicrosoftteamsdownloadapp><u>Download Teams<u><a>  <a hrefhttps:www.microsoft.commicrosoftteamsjoinameeting><u>Join on the web<u><a><br><br><b>Or call in audio only<b><br><a><u>39 02 3056 4191,,780108878#<u><a>   Italy, MilanoPhone Conference ID: 780 108 878#<br><a hrefhttps:dialin.teams.microsoft.come80d62af367c4976959661ef054e4984id780108878><u>Find a local number<u><a>  <a hrefhttps:dialin.teams.microsoft.comusppstnconferencing><u>Reset PIN<u><a><br><a hrefhttps:aka.msJoinTeamsMeeting><u>Learn More<u><a>  <a hrefhttps:teams.microsoft.commeetingOptionsorganizerId729b4d16056746a8a742d2ae1bf09a4atenantIdc7456b31a22047f5be52473828670aa1threadId199a85abed0d8544a8bc86e6f8f42e599dthread.tacv2messageId1671204581740languageenUS><u>Meeting options<u><a>
                