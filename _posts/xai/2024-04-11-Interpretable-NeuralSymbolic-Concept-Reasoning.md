---
layout: post
title: "Interpretable NeuralSymbolic Concept Reasoning"
event-date: "2024-04-11 11:00:00"
date: "2024-04-11 11:00:00"
year: 2024
tags: "seminar"
location: "Officine Garibaldi - il Cantiere delle Idee, Via Vincenzo Gioberti, 39, 56124 Pisa PI, Italy"
presenter: "Presenter: Francesco Giannini, Marco Gori"
---
<h5>Presenter: Francesco Giannini, Marco Gori</h5>
<em>Location: Officine Garibaldi - il Cantiere delle Idee, Via Vincenzo Gioberti, 39, 56124 Pisa PI, Italy<em>
<br>
<hr>



Abstract: Deep learning methods are highly accurate, yet their opaque decision process prevents them from earning full human trust. Concept-based models aim to address this issue by learning tasks based on a set of human-understandable concepts. However, state-of-the-art concept-based models rely on high-dimensional concept embedding representations which lack a clear semantic meaning, thus questioning the interpretability of their decision process. To overcome this limitation, we propose the Deep Concept Reasoner (DCR), an interpretable concept-based model that builds upon concept embeddings. In DCR, neural networks do not make task predictions directly, but they build syntactic rule structures using concept embeddings. DCR then executes these rules on meaningful concept truth degrees to provide a final interpretable and semantically-consistent prediction in a differentiable manner.

                