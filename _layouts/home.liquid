---
layout: default
---
<header>
    <div class="row justify-content-center pt-5 pb-5 section-alt ">
        <div class="col-lg-4 col-md-8s">
            <h3 class="text-uppercase py-lg-6 mb-0">Science and technology for the explanation of ai decision
                making.</h3>
            <p class="lead mb-5 mt-sm-3">
                The <strong>ERC Xai project</strong> focuses on the urgent open challenge of how to construct meaningful
                explanations of opaque AI/ML systems in the context of ai based decision making, aiming at empowering
                individual against undesired effects of automated decision making, implementing the “right of
                explanation”, helping people make better decisions preserving (and expand) human autonomy.

            </p>
        </div>
        <div class="col-lg-4 pt-lg-2 pb-lg-7 mt-lg-8">
            <div class="card">
                <div class="py-lg-6 px-lg-6 py-md-5 px-md-5 py-5 px-4">
                    <a href="https://cordis.europa.eu/project/id/834756"
                       target="_blank">
                        <h4 class="mb-3">ERC Project Information</h4>
                        <div class="lead">
                            <p class="mb-0">Grant agreement ID: 834756</p>
                            <p class="mb-0">Call: <em>ERC-2018-ADG</em></p>
                            <p class="mb-0">Total cost: <em>2 500 000€</em></p>
                            <p class="mb-4">EU Contribution: <em>2 500 000€</em></p>
                            <p class="mb-0">PI: <em>Fosca Giannotti</em></p>
                            <p class="mb-0">Email: <em>fosca.giannotti @ sns.it</em></p>
                        </div>
                    </a></div>
            </div>
        </div>
    </div>
</header>
<div class="container pt-5">

    <article class="pb-3">
        {% if page.profile %}
            <div class="profile float-{% if page.profile.align == 'left' %}left{% else %}right{% endif %}">
                {% if page.profile.image %}
                    {% assign profile_image_path = page.profile.image | prepend: 'assets/img/' %}
                    {% if page.profile.image_circular %}
                        {% assign profile_image_class = 'img-fluid z-depth-1 rounded-circle' %}
                    {% else %}
                        {% assign profile_image_class = 'img-fluid z-depth-1
      rounded' %}
                    {% endif %}
                    {% capture sizes %}(min-width: {{ site.max_width }}) {{ site.max_width | minus: 30 | times: 0.3 }}px, (min-width: 576px)
                        30vw, 95vw"{% endcapture %}
                    {%
                            include figure.liquid loading="eager" path=profile_image_path class=profile_image_class sizes=sizes alt=page.profile.image
                            cache_bust=true
                    %}
                {% endif %}
                {% if page.profile.more_info %}
                    <div class="more-info">{{ page.profile.more_info }}</div>
                {% endif %}
            </div>
        {% endif %}
        <div class="lead">
            <p>Black box AI systems for automated decision making, often based on ML over (big) data, map a user’s
                features into a class or a score without exposing the reasons why. This is problematic both for the lack
                of transparency and also for possible biases inherited by the algorithms from prejudices and collection
                artifacts hidden in the training data, which may lead to unfair or wrong decisions. The future of AI
                lies in enabling people to collaborate with machines, requiring good communication, trust, clarity, and
                understanding.</p>
        </div>
        <div>
            <p>This project aims at developing:</p>
            <ol>
                <li>an explanation infrastructure for benchmarking, equipped with platforms for the users' assessment of
                    the explanations;
                </li>
                <li>an ethical-legal framework, in compliance with the provisions of the GDPR;</li>
                <li>a repertoire of case studies in explanation-by-design, mainly focused on health and fraud detection
                    applications.
                </li>
            </ol>

                <button class="btn">
                    <a href="/about">More on the project</a>
                </button>

        </div>
    </article>
</div>

<hr>

<div class="container pt-5">
    <div class="clearfix">{{ content }}</div>


    <!-- News -->
    {% if page.news and site.announcements.enabled %}
        <h2>
            <a href="{{ '/news/' | relative_url }}"
               style="color: inherit">news</a>
        </h2>
        {% include news.liquid limit=true %}
    {% endif %}

    <!-- Latest posts -->
    {% if site.latest_posts.enabled %}
        <h2>
            <a href="{{ '/blog/' | relative_url }}"
               style="color: inherit">latest posts</a>
        </h2>
        {% include latest_posts.liquid %}
    {% endif %}

    <!-- Selected papers -->
    {% if page.selected_papers %}
        <h2>
            <a href="{{ '/publications/' | relative_url }}"
               style="color: inherit">selected publications</a>
        </h2>
        {% include selected_papers.liquid %}
    {% endif %}

    <!-- Social -->
    {% if page.social %}
        <div class="social">
            <div class="contact-icons">{% include social.liquid %}</div>

            <div class="contact-note">{{ site.contact_note }}</div>
        </div>
    {% endif %}
</div>
