---
layout: article
date: '2024-04-18 00:00:00-0000'
event-date: '2024-04-18 00:00:00-0000'
inline: False
onlylink: False
related_posts: false
categories: 'Workshop'
permalink: '/news/ReasonX'
title: 'ReasonX, declarative, interactive explanations for decision trees'
thumb: '/assets/img/news/workflow_reason_x.png'
link: 'https://github.com/lstate/REASONX'
---
REASONX provides declarative, interactive explanations for decision trees, which can be the ML models under analysis, or global/local surrogate models of any black-box model (i.e., model-agnostic). Additionally, it can incorporate background or common sense knowledge in the form of linear constraints. Explanations are provided as factual and contrastive rules, and in the form of closest contrastive examples via MILP optimization.

Here, we provide both the Prolog program, as well as a Python layer to access REASONX.

More information can be found in our papers:

1.  Accepted at [JELIA 2023](https://jelia2023.inf.tu-dresden.de/)A [paper](http://export.arxiv.org/abs/2309.00422) on the theoretical background of REASONX (Constraint Logic Programming, Prolog, Meta-Interpreter).
    
2.  Accepted at [xAI 2023](https://xaiworldconference.com/)An interdisciplinary [paper](https://arxiv.org/abs/2305.18143), demonstrating main capabilites of REASONX via a synthetic example, and based on the Adult Income Dataset.
